%%
%% Copyright 2022 OXFORD UNIVERSITY PRESS
%%
%% This file is part of the 'oup-authoring-template Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'oup-authoring-template Bundle' is
%% given in the file `manifest.txt'.
%%
%% Template article for OXFORD UNIVERSITY PRESS's document class `oup-authoring-template'
%% with bibliographic references
%%

%%%CONTEMPORARY%%%
% \documentclass[unnumsec,webpdf,contemporary,large]{oup-authoring-template}%
\documentclass[numsec,webpdf,contemporary,medium,namedate]{oup-authoring-template}% uncomment this line for author year citations and comment the above
%\documentclass[unnumsec,webpdf,contemporary,medium]{oup-authoring-template}
%\documentclass[unnumsec,webpdf,contemporary,small]{oup-authoring-template}

%%%MODERN%%%
%\documentclass[unnumsec,webpdf,modern,large]{oup-authoring-template}
% \documentclass[unnumsec,webpdf,modern,large,namedate]{oup-authoring-template}% uncomment this line for author year citations and comment the above
%\documentclass[unnumsec,webpdf,modern,medium]{oup-authoring-template}
%\documentclass[unnumsec,webpdf,modern,small]{oup-authoring-template}

%%%TRADITIONAL%%%
%\documentclass[unnumsec,webpdf,traditional,large]{oup-authoring-template}
% \documentclass[unnumsec,webpdf,traditional,large,namedate]{oup-authoring-template}% uncomment this line for author year citations and comment the above
%\documentclass[unnumsec,namedate,webpdf,traditional,medium]{oup-authoring-template}
%\documentclass[namedate,webpdf,traditional,small]{oup-authoring-template}

\onecolumn % for one column layouts

%\usepackage{showframe}

% \graphicspath{{Fig/}}

% line numbers
%\usepackage[mathlines, switch]{lineno}
%\usepackage[right]{lineno}

\theoremstyle{thmstyleone}%\
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
% \newtheorem{proposition}[theorem]{Proposition}%
% to get separate numbers for theorem and proposition etc.:
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%
\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}



%% OLD

% \usepackage{natbib, dsfont,
% amssymb,soul,xcolor,amsmath,graphicx,verbatim,pgfplots,tikz,prodint,booktabs}

\usepackage{dsfont, booktabs}

\usepackage[tablesonly,heads,nolists]{endfloat}


%% Only for comments:
\usepackage[author=]{fixme}
\fxusetheme{color}
\definecolor{fxtarget}{rgb}{.5,.5,.5}
\definecolor{fxnote}{rgb}{.5,.5,.5}
\fxsetup{status=draft}

% \bibliographystyle{rss}

%% Toggle with or without figures
% \def\nofig{1}

\newcommand{\includeFigCond}[2][]{
  \ifx\nofig\undefined %
    \includegraphics[#1]{#2} %
  \else %
    \texttt{#2} %
  \fi %
}

% New operators and commands
\DeclareMathOperator{\E}{\mathbb{E}} % expectation
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\renewcommand{\S}{\mathbb{S}}
\newcommand{\blank}{\makebox[1ex]{\textbf{$\cdot$}}}
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\renewcommand{\phi}{\varphi}
\renewcommand{\epsilon}{\varepsilon}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand{\weakly}{\rightsquigarrow}
\newcommand\smallO{\textit{o}}
\newcommand\bigO{\textit{O}}
\newcommand{\midd}{\; \middle|\;}
\newcommand{\1}{\mathds{1}}
\usepackage{ifthen} %% Empirical process with default argument
% \newcommand{\G}[1][]{%
%    \ifthenelse{ \equal{#1}{} }
%       {\ensuremath{\mathbb{G}_n}}
%       {\ensuremath{\mathbb{G}_{#1}}}
% }
% New version:
\newcommand{\G}[2][n]{
{\ensuremath{\mathbb{G}_{#1}}{\left[#2\right]}}
}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\argmax}{\arg\!\max}
\newcommand{\empmeas}{\ensuremath{\mathbb{P}_n}} % empirical measure

\newcommand{\data}{\ensuremath{\mathcal{D}}}


\begin{document}

%% NEW

\journaltitle{Journal of the Royal Statistical Society Series B: Statistical
  Methodology} %
\DOI{DOI HERE} %
\copyrightyear{xxxx} %
\pubyear{yyyy} \access{Advance Access Publication Date: Day Month Year}
\appnotes{Paper}


\firstpage{1}

%\subtitle{Subject Section}

\title[The state learner]{The state learner -- a super learner for
  right-censored data}

\author[1,$\ast$]{Anders Munch}
\author[1]{Thomas A.\ Gerds}

\authormark{Munch et al.}

\address[1]{\orgdiv{Section of Biostatistics}, \orgname{University of
    Copenhagen}, \orgaddress{\street{Ã˜sterfarigmagsgade 5}, \postcode{2100}, \state{Copenhagen}, \country{Denmark}}}

\corresp[$\ast$]{Address for correspondence: \href{email:email-id.com}{a.munch@sund.ku.dk}}

% \received{Date}{0}{Year}
% \revised{Date}{0}{Year}
% \accepted{Date}{0}{Year}


\abstract{In survival analysis, prediction models are needed as stand-alone
  tools and in applications of causal inference to estimate nuisance parameters.
  The super learner is a machine learning algorithm which combines a library of
  prediction models into a meta learner based on cross-validated loss. In right
  censored data, loss needs to be estimated somehow. We introduce the state
  learner, a new super learner for survival analysis, which simultaneously
  evaluates libraries of prediction models for the event of interest and the
  censoring distribution. The state learner can be applied to all types of
  survival models, works in the presence of competing risks, and does not
  require a single pre-specified estimator of the conditional censoring
  distribution. We establish an oracle inequality for the state learner and
  investigate its performance through numerical experiments. We illustrate how
  the state learner allows us to estimate causal effects in a competing risks
  setting without having to pre-specify models for neither the cause-specific
  hazards of interest nor the censoring distribution.}

\keywords{Competing risks, cross-validation, loss based estimation,
  right-censored data, super learner}

\maketitle

\section{Introduction}
\label{sec:introduction}

Medical decision making is traditionally based on the discrepancy
between intuitive judgment and the law of chance
\citep{redelmeier1995probability}. We are concerned with the
statistical models that provide probabilistic predictions about the
medical future of a patient. We have two different applications of
these models in mind. One is as a stand-alone tool where the model
provides information for a freshly diagnosed patient. The other is as
input to an algorithm which estimates a causal target parameter such
as an average treatment effect. The models are learned on data from
previous patients. A super learner is a machine learning algorithm
that combines a finite set of learners into a meta learner by
estimating prediction performance in hold-out samples using a
pre-specified loss function \citep{van2007super}. When the aim is to
make a prediction model, super learners combine strong learners, such
as Cox regression models and random survival forests
\citep{gerds2021medical}.
% For targeted learning of a low dimensional
% target parameter in presence of a high-dimensional nuisance parameter,
% a super learner will usually also include the highly adaptive lasso
% \citep{van2011targeted, benkeser2016highly,van2017generally}.
While the general idea of combining strong learners based on cross-validation
data stems from earlier work \citep{wolpert1992stacked,breiman1996stacked}, the
name super learner is justified by an oracle inequality
\citep{van2003unicv,vaart2006oracle}: The super learner is guaranteed to perform
almost as well as the model which minimises the expected performance, i.e., the
model we would select if we could evaluate the prediction performance in an
infinite hold-out sample.

The choice of
the loss function for super learning in survival analysis deserves a
closer look. Existing super learner algorithms for right-censored data
use partial log-likelihood loss or inverse probability of censoring
weighted loss
\citep{polley2011-sl-cens,keles2004asymptotically,golmakani2020super,gonzalez2021stacked,westling2021inference}.
The use of the partial log-likelihood loss, however, restricts the
class of learners and excludes for example simple Kaplan-Meier based
learners and also more complex random survival forest algorithms. For
this reason \cite{golmakani2020super} restrict their learners to Cox
proportional hazard models. A lesser known fact is that a super
learner constructed with the negative partial log-likelihood loss
implicitly depends on the censoring distribution
\citep{hjort1992inference,whitney2019comment}. Inverse probability of
censoring weighted loss has been studied for decades
\citep{graf1999assessment, hothorn2006survival,
  gerds2006consistent}. A disadvantage of inverse probability of
censoring weighted loss estimators is that they require a
pre-specified model for the censoring distribution. Recently
\cite{westling2021inference} proposed a procedure which iterates
between super learning of the censoring distribution and super
learning of the event time distribution. We pursue a
different route.

In this article we define the state learner, a new super learner for
right-censored data, which simultaneously estimates the expected loss of
learners of the event time distribution and the censoring distribution. The loss
function which is used to define the state learner is based on the observed
variables, that is, the minimum and the order of the censoring time and the
event time.

The state learner can be applied to all types of survival models,
it can handle competing risks, and it does not require a
single pre-specified estimator of the conditional censoring
distribution.  To analyze the theoretical properties of the state
learner we focus on the discrete super learner which combines the
library of learners by picking the one that minimises the
cross-validated loss \citep{van2007super}. In the presence of
competing risks, our algorithm uses separate libraries to model the
cumulative hazard functions of the competing risks and the censoring
distribution. We show that the oracle selector of the state learner is
consistent if all libraries contain a consistent learner and prove a
finite sample oracle inequality. A result of the state learner
algorithm is a model which predicts the probability of an event based
on covariates in the presence of competing risks
\citep{gerds2021medical}. The other application is in targeted
learning where conditional event probabilities occur as
high-dimensional nuisance parameters which need to be estimated at a
certain rate \citep{van2011targeted, rytgaard2021estimation,
  rytgaard2022targeted}. We show for a targeted estimator, which uses
the state learner to estimate nuisance parameters, that a second order
product structure holds for the asymptotic bias term.

The article is organised as follows. We introduce our notation and
framework in Section~\ref{sec:framework}. In
Section~\ref{sec:super-learning} we define general super learning
for right-censored data, and in Section~\ref{sec:relat-liter-exist}
we review existing methods.  Section~\ref{sec:super-learner-simple}
introduces our novel proposal, the state learner, and
Section~\ref{sec:theor-results-prop} provides theoretical guarantees
for the state learner. In Section~\ref{sec:targeted-learning} we
discuss the use of the state learner in the context of targeted
learning. We report results of our numerical experiments in
Section~\ref{sec:numer-exper} and analyze a prostate cancer data set
in Section~\ref{sec:real-data-appl}.  Section~\ref{sec:discussion}
contains a discussion of the merits and limitations of our
proposal. Appendices~\ref{sec:proof-proposition}
and~\ref{sec:state-learner-with} contain proofs.


\section{Notation and framework}
\label{sec:framework}

In a competing risk framework \citep{andersen2012statistical}, let \( T\) be a
time to event variable, \(D\in\{1,2\}\) the cause of the event, and
$X \in \mathcal{X}$ a vector of baseline covariates taking values in a bounded
subset \( \mathcal{X} \subset \R^p \), \( p\in\N \). Let $\tau< \infty$ be the
maximal length of follow-up. We use \( \mathcal{Q} \) to denote the collection
of all probability measures on \( [0,\tau] \times \{1,2\}\times \mathcal{X} \)
such that \( (T, D, X) \sim Q \) for some unknown \( Q \in \mathcal{Q} \). For
\(j\in\{1,2\}\), the cause-specific conditional cumulative hazard functions are
defined by
\( \Lambda_{j} \colon [0, \tau] \times \mathcal{X} \rightarrow \R_+ \) such that
\begin{equation*}
  % \label{eq:cum-haz}
  \Lambda_{j}(t \mid x) = \int_0^t\frac{  Q(T \in \diff s, D=j \mid X=x )}{Q(T \geq s \mid X=x )}.
\end{equation*}
For ease of presentation we assume throughout that
\( \Lambda_j(\blank \mid x) \) is continuous for all \( x \) and
\( j \). This is not a limitation as everything caries over directly
to the general case. We denote by \(S\) the conditional event-free
survival function:
\begin{equation}
  \label{eq:surv-def}
  S(t \mid x)=\exp\left\{-\Lambda_{1}(t \mid x)-\Lambda_{2}(t \mid x)\right\}.
\end{equation}
Let \( \mathcal{M}_{\tau}\) denote the space of all conditional cumulative hazard
functions on \( [0,\tau] \times\mathcal{X}\). Any distribution
\( Q \in \mathcal{Q} \) can be characterised by
\begin{equation*}
  \label{eq:parametrizeQ}
  \begin{split}
    Q(\diff t,j,\diff x)=& \left\{S(t- \mid x)\Lambda_1(\diff t \mid x)H(\diff x)\right\}^{\1{\{j=1\}}}\\
                         &  \left\{S(t- \mid x)\Lambda_2(\diff t \mid x)H(\diff x)\right\}^{\1{\{j=2\}}},
  \end{split}
\end{equation*}
where \(\Lambda_{j} \in \mathcal{M}_{\tau}\) for \(j=1,2\) and \(H\) is the marginal
distribution of the covariates.

We consider the right-censored setting in which we observe data
\(O = (\tilde{T},\tilde D, X)\), where $\tilde T = \min(T,C)$ for a
right-censoring time \(C\), $\Delta = \1{\{T \leq C\}}$, and
\(\tilde D=\Delta D\). Let \(\mathcal{P}\) denote a set of probability
measures on the sample space
\(\mathcal{O} = [0, \tau] \times \{0, 1, 2\} \times \mathcal{X}\) such
that \(O \sim P \) for some unknown \(P\in \mathcal{P}\). We assume
that the event times and the censoring times are conditionally
independent given covariates, \( T \independent C \mid X \). This
implies that any distribution \( P \in \mathcal{P} \) is characterised
by a distribution \( Q \in \mathcal{Q} \) and a conditional cumulative
hazard function for \( C \) given \( X \)
\citep[c.f.,][]{begun1983information,gill1997coarsening}. We use
\(\Gamma\in\mathcal M\) to denote the conditional cumulative hazard
function for censoring. For ease of presentation we now also assume
that \( \Gamma(\blank \mid x) \) is continuous for all \( x \). We let
\(G(t \mid x)=\exp\left\{-\Gamma(t \mid x)\right\}\) denote the
survival function of the conditional censoring distribution. The
distribution \( P \) is characterised by
\begin{equation}\label{eq:parametrizeP}
  \begin{split}
    P(\diff t, j, \diff x) =& \left\{G(t- \mid x)S(t- \mid x)\Lambda_1(\diff t \mid x)H(\diff x)\right\}^{\1{{\{j=1\}}}}\\
                            & \left\{G(t- \mid x)S(t- \mid x)\Lambda_2(\diff t \mid x)H(\diff x)\right\}^{\1{{\{j=2\}}}}\\
                            & \left\{G(t- \mid x)S(t- \mid x)\Gamma(\diff t \mid x)H(\diff x)\right\}^{\1{{\{j=0\}}}}\\
    = & \left\{G(t- \mid x)Q(\diff t,j,\diff x)\right\}^{\1{{\{j\ne 0\}}}}\\    
                            & \left\{G(t- \mid x)S(t- \mid x)\Gamma(\diff t \mid x)H(\diff x)\right\}^{\1{{\{j=0\}}}}.
  \end{split}
\end{equation}
Hence, we may write
\( \mathcal{P} = \{ P_{Q, \Gamma} : Q \in \mathcal{Q}, \Gamma \in
\mathcal{G} \} \) for some \( \mathcal{G} \subset \mathcal{M}_{\tau} \). We
also have \(H\)-almost everywhere
\begin{equation*}
P(\tilde T>t \mid X=x) = S(t \mid x)G(t \mid x) = \exp\left\{-\Lambda_{1}(t \mid x)-\Lambda_{2}(t \mid x)-\Gamma(t \mid x) \right\}.
\end{equation*}
We further assume that there exists \(\kappa<\infty\) such that
\(\Lambda_{j}(\tau- \mid x)<\kappa \), for \(j\in\{1,2\}\), and
\(\Gamma(\tau- \mid x)<\kappa\) for almost all \(x\in\mathcal X\). Note that this
implies that \(G(\tau- \mid x)\) is bounded away from zero for almost all \(x\in\mathcal X\).
Under these assumptions, the conditional cumulative hazard functions
\(\Lambda_{j}\) and \(\Gamma\) can be identified from \(P\) by
\begin{align}
  \Lambda_{j}(t \mid x) &= \int_0^t\frac{  P(\tilde T \in \diff s, \tilde D=j \mid X=x )}{P(\tilde T \geq s \mid X=x )}, \label{eq:lambdaj}\\
  \Gamma(t \mid x) &= \int_0^t\frac{  P(\tilde T \in \diff s, \tilde D=0 \mid X=x )}{P(\tilde T \geq s \mid X=x )}\label{eq:gamma}.
\end{align}
Thus, we can consider $\Lambda_j$ and \(\Gamma\) as operators which map from
\( \mathcal{P} \) to \(\mathcal M\).

 
\section{The concept of super learning}
\label{sec:super-learning}

In survival analysis, a super learner can be used to estimate a
parameter $\Psi$ which can be identified from the observed data
distribution \(P\in\mathcal P\). In this section, to introduce the
discrete super learner and the oracle learner, we consider estimation of the
function-valued parameter \(\Psi:\mathcal P\to\mathcal M\), given by
\(\Psi(P)=\Lambda_j\). This parameter is identified via equation
\eqref{eq:lambdaj} on \([0,\tau]\).

As input to the super learner we need a data set
\( \data_n=\{O_i\}_{i=1}^n \) of i.i.d.\ observations from \( P \in \mathcal{P} \) and a finite collection of candidate
learners $\mathcal{A}$. Each learner \(a \in \mathcal{A}\) is a map
\( a \colon \mathcal{O}^n \rightarrow \mathcal{M}_{\tau}\) which takes a data
set as input and returns an estimate $a(\data_n) \in \mathcal{M}_{\tau}$ of
$\Lambda_{j}$.
% Formally, the domain of $a$ depends on \(n\) but we suppress this in the notation.
In what follows, we use the short-hand notation
\(P[f] = \int f(o) P(\diff o) \). A super learner evaluates the
performance of \(a \in \mathcal{A}\) with a loss function
\(L\colon \mathcal{M}_{\tau} \times \mathcal{O} \rightarrow \R_+\) and
estimates the expected loss \(P[L(a(\data_n), \blank)]\) using
cross-validation. Specifically, the expected loss of $a\in\mathcal A$
is estimated by splitting the data set $\data_n$ into $K$ disjoint
approximately equally sized subsets
\(\data_n^1, \data_n^2, \dots, \data_n^K \) and then calculating the
cross-validated loss
\begin{equation*}
  % \label{eq:cv-risk-est}
  \hat{R}_n(a; L) =
  \frac{1}{K}\sum_{k=1}^{K}
  % \empmeas^k{[L {(a{ (\data_n^{-k})} , \blank) }]},
  \frac{1}{| \data_n^{k} |}\sum_{O_i \in \data_n^{k}}
  L
  {
    \left(
      a{ (\data_n^{-k})}
      , O_i
    \right)
  },
  \quad \text{with} \quad
  \data_n^{-k} = \data_n \setminus \data_n^{k}.
\end{equation*}
% where \( \empmeas^{k} \) is the empirical measure of \( \data_n^{k} \). 
The subset \(\data_n^{-k}\) is referred to as the \(k\)'th training
sample, while \(\data_n^{k}\) is referred to as the \(k\)'th test or
hold-out sample.
The discrete super learner is defined as
\begin{equation*}
\hat{a}_n = \argmin_{a\in\mathcal A}\hat{R}_n(a; L).
\end{equation*}
% The final estimator of \(\Psi(P)=\Lambda_j\) is then the selected
% learner applied to the full data set, i.e., \(\hat{a}_n(\data_n)\).
The oracle learner is defined as the learner that minimises the
average loss according to the data-generating distribution \( P \),
i.e.,
\begin{equation*}
  \tilde{a}_n =
  \argmin_{a \in \mathcal{A}}
  \tilde{R}_n(a; L),
  \quad \text{with} \quad 
  \tilde{R}_n(a; L)=
  \frac{1}{K}\sum_{k=1}^{K} 
  P{
    \left[
      L
      {
        \left(
          a{ (\data_n^{-k})}
          , \blank
        \right)
      }
    \right]}
  .
\end{equation*}
Note that both the discrete super learner and the oracle learner
depend on the library of learners and on the number of folds \(K\),
and that the oracle learner is a function of the data and the unknown
data-generating distribution. However, these dependencies are
suppressed in the notation.

\section{Existing methods}
\label{sec:relat-liter-exist}

Machine learning based on right-censored data commonly use the
negative partial log-likelihood as loss function
\citep[e.g.,][]{li2016regularized,yao2017deep,lee2018deephit,katzman2018deepsurv,gensheimer2019scalable,lee2021boosted,kvamme2021continuous}.
This loss function is however not perfectly suited for super
learning. The reason is that it cannot be applied to important
survival learners: The Kaplan-Meier estimator, the random survival
forest, and the semi-parametric Cox regression model provide
cumulative hazard functions that are piece-wise constant in the time
argument. Suppose these methods are applied to a learning data set and
the aim is to evaluate the partial log-likelihood loss in an
independent test data set. Suppose further that the test data set
contains event times that were not also seen in the learning data set,
as it would naturally happen when the events are observed in
continuous time. The problem is that these methods assign zero
probability to the test set event times that were not also in the
training data set, and hence (the logarithm of zero is infinity) the
partial log-likelihood loss in the test set would be infinity.

When a proportional hazards model is assumed, the baseline hazard
function can be profiled out of the likelihood \citep{cox1972regression}.
The cross-validated partial log-likelihood loss  \citep{verweij1993cross} has therefore been
suggested as a loss function for super learning which however
restricts the library of learners to include only Cox proportional
hazards models \citep{golmakani2020super}.

Another approach for super learning with right-censored data is to use an
inverse probability of censoring weighted (IPCW) loss function
\citep{graf1999assessment,van2003unicv,molinaro2004tree,keles2004asymptotically,hothorn2006survival,gerds2006consistent,gonzalez2021stacked}.
An IPCW loss function is attractive because the associated risk does not depend
on the censoring distribution but describes a feature of the population of
interested governed by the measure \( Q \in \mathcal{Q} \). Similar results can
be obtained using censoring unbiased transformations
\citep{fan1996local,steingrimsson2019censoring} or pseudo-values
\citep{andersen2003generalised,mogensen2013random,sachs2019ensemble}. All these
methods rely on an estimator of the censoring distribution, and their drawback
is that this estimator has to be pre-specified. When the data-generating
mechanism is complex and not well-understood, pre-specification of the censoring
distribution is a challenge.

An attempt to avoid a pre-specified censoring model was proposed
independently by \cite{han2021inverse} and
\cite{westling2021inference}. In both articles, the authors suggest to
iterate between learning of \( \Lambda \) and learning of $\Gamma$
using IPCW loss functions. However, no general theoretical guarantees
seem to exist for this procedure, and it has not yet been extended to
the situation with competing risks.

\section{The state learner}
\label{sec:super-learner-simple}

% The problem with most existing super learners for right-censored data is that
% they depend on a pre-specified estimator of the censoring distribution.
The main idea of the state learner is to jointly use learners of
\( \Lambda_1 \), \( \Lambda_2 \), and \( \Gamma \), and the relations in
equation~(\ref{eq:parametrizeP}), to learn a feature of the observed data
distribution \( P \). The discrete state learner ranks a tuple of learners of
\( (\Lambda_1, \Lambda_2, \Gamma) \) based on how well they jointly model the
observed
data.
Risk predictions can then be obtained from
\( \Lambda_1 \) and $\Lambda_2$ \citep{benichou1990estimates, ozenne2017riskregression}. To formally
introduce the state learner, we define the multi-state process
\begin{equation*}
  \eta(t) = \1\{\tilde{T} \leq t, \tilde D=1\} + 2\,\1\{\tilde{T} \leq t, \tilde
  D=2\} - \1\{\tilde{T} \leq t, \tilde D=0\},
  \quad \text{for} \quad t \in [0, \tau].
\end{equation*}
At time \(t\), we observe that each individual is in one of four mutually
exclusive states (Figure \ref{fig:multi-state-process}).

\begin{figure}[h]
  \centering %
  \includeFigCond[width=.5\textwidth]{figure-multi-state-process.pdf}
  \caption{Illustration of the multi-state process \(\eta\) used by
    the state learner. Note that `censored' is a state, hence the
    process is always observed at any time.}
  \label{fig:multi-state-process}
\end{figure}

The conditional
distribution of \( \eta(t) \) given \( X \) is determined by the function
\begin{equation}
  \label{eq:F-def}
  F(t, k, x) = P(\eta(t) = k \mid X=x),
  \quad \text{for all} \quad
  t \in [0,\tau],
  k \in \{-1,0,1,2\},
  x \in \mathcal{X}.
\end{equation}
The function \( F \) describes the conditional state occupation
probabilities of the multi-state process \(\eta\). We construct a
super learner for \( F \). The target of this super learner is the
function-valued parameter $\Psi(P) = F$ which is identified through
equation~(\ref{eq:F-def}).
Under conditional independent censoring each quadruple
$(\Lambda_{1}, \Lambda_{2}, \Gamma, H)$ characterises a distribution
\(P\in\mathcal P\), c.f.\ equation~\eqref{eq:parametrizeP}, which in turn
determines \( (F, H) \),
and so a learner for \( F \) can be constructed from learners of
\( \Lambda_1 \), \( \Lambda_2 \), and $\Gamma$ as follows:
\begin{equation}\label{eq:transition}
  \begin{split}
  F(t, 1, x)
  & = P(\tilde{T} \leq t, \Delta=1 \mid X=x)
    = \int_0^t e^{\{-\Lambda_{1}(s \mid x)-\Lambda_{2}(s \mid x) - \Gamma(s \mid x)\} }  \Lambda_{1}(\diff s \mid x),
  \\
  F(t, 2, x)
  & = P(\tilde{T} \leq t, \Delta=2 \mid X=x)
    = \int_0^t e^{\{-\Lambda_{1}(s \mid x)-\Lambda_{2}(s \mid x) - \Gamma(s \mid x)\} }  \Lambda_{2}(\diff s \mid x),
  \\
  F(t, -1, x)
  & =
    P(\tilde{T} \leq t, \Delta=0 \mid X=x)
    = \int_0^t e^{\{-\Lambda_{1}(s \mid x)-\Lambda_{2}(s \mid x) - \Gamma(s \mid x)\} }  \Gamma(\diff s \mid x),
  \\
  F(t, 0, x)
  &
    = P(\tilde{T} > t \mid X= x)
    = 1- F(t, 1, x) - F(t, 2, x)- F(t, -1, x).
  \end{split}
\end{equation}
The state learner requires three libraries of learners,
\(\mathcal{A}_1\), \( \mathcal{A}_2 \), and \( \mathcal{B} \), where
\(\mathcal{A}_1\) and \( \mathcal{A}_2\) contain learners of the
conditional cause-specific cumulative hazard functions \(\Lambda_1\)
and \( \Lambda_2\), respectively, and \(\mathcal{B}\) contains
learners of the conditional cumulative hazard function of the
censoring distribution. % We further
% define \(\mathcal{H}\) as the set of all probability distributions on
% \( \mathcal{X} \) and
% \begin{equation*}
%   \mathcal{H}_n=\left\{h\colon\mathcal{O}^n\longrightarrow\mathcal{H} \midd
%     h(\data_n)=H_n = \frac 1 n \sum_{i=1}^n \delta_{X_i} \right\}
% \end{equation*}
% as the library of learners which consists of a single learner, the empirical
% distribution function.
Based on the Cartesian product of
libraries of learners for \((\Lambda_1,\Lambda_2,\Gamma)\) we construct a library
$\mathcal{F}$ of learners
for \( F \):
\begin{align*}
  \mathcal{F}(\mathcal{A}_1, \mathcal{A}_2, \mathcal{B})
  &= \{ \phi_{a_1,a_2, b} : a_1 \in \mathcal{A}_1, a_2 \in \mathcal{A}_2, b \in \mathcal{B}\},
    \intertext{where in correspondence with  the relations in equation \eqref{eq:transition},} 
    \phi_{a_1,a_2, b}(\data_n)(t,1,x) &= \int_0^t e^{\{-a_1(\data_n)(s \mid x)-a_2(\data_n)(s \mid x) - b(\data_n)(s \mid x)\} }  a_1(\data_n)(\diff s \mid x),\\
  \phi_{a_1,a_2, b}(\data_n)(t,2,x) &= \int_0^t e^{\{-a_1(\data_n)(s \mid x)-a_2(\data_n)(s \mid x) - b(\data_n)(s \mid x)\} }  a_2(\data_n)(\diff s \mid x),\\
  \phi_{a_1,a_2, b}(\data_n)(t,-1,x) &= \int_0^t e^{\{-a_1(\data_n)(s \mid x)-a_2(\data_n)(s \mid x) - b(\data_n)(s \mid x)\} }  b(\data_n)(\diff s \mid x),\\
  \phi_{a_1,a_2, b}(\data_n)(t,0,x) &= 1
                                      - \phi_{a_1,a_2, b}(\data_n)(t,1,x)
                                      - \phi_{a_1,a_2, b}(\data_n)(t,2,x)
    -\phi_{a_1,a_2, b}(\data_n)(t,-1,x)
\end{align*}
To evaluate how well a function \( F \) predicts the observed
multi-state process we use the integrated Brier score
\( \bar B_\tau( F,O) = \int_0^{\tau} B_t(F,O) \diff t \), where \( B_t \) is the
Brier score \citep{brier1950verification} at time \( t \in [0, \tau] \),
\begin{equation*}
  B_t(F,O) = \sum_{j=-1}^{2}
  \left(
      F(t,j,X) - \1{\{\eta(t)=j\}}
  \right)^2.
\end{equation*}
Based on a split of a data set \(\data_n\) into $K$ disjoint
approximately equally sized subsets (see Section \ref{sec:super-learning}), each learner
\( \phi_{a_1, a_2, b} \) in the library
\( \mathcal{F}(\mathcal{A}_1, \mathcal{A}_2, \mathcal{B}) \) is
evaluated using the cross-validated loss,
\begin{equation*}
  \hat{R}_{n}(\phi_{a_1,a_2,b} ; \bar{B}_{\tau}) =
  \frac{1}{K}\sum_{k=1}^{K}
  \frac{1}{| \data_n^{k} |}\sum_{O_i \in \data_n^{k}}
  \bar B_\tau
  {
    \left(
      \phi_{a_1,a_2,b}{ (\data_n^{-k})}
      , O_i
    \right)
  },
\end{equation*}
and the discrete state learner is given by
\begin{align*}\label{eq:discrete-state-learner}
  \hat{\phi}_n
  &=  \argmin_{(a_1,a_2,b)\in \mathcal{A}_1\times\mathcal{A}_2\times\mathcal{B}}
    \hat{R}_{n}(\phi_{a_1,a_2,b} ; \bar{B}_{\tau}).
\end{align*}


\section{Theoretical results for the state learner}
\label{sec:theor-results-prop}

In this section we establish theoretical guarantees for the state learner. We
show that the state learner is consistent if its library contains a consistent
learner, and we establish a finite sample inequality for the excess risk of the
state learner compared to the oracle. Finally we show that a certain second
order structure is preserved when the state learner is used for targeted
learning.

\subsection{Consistency}
\label{sec:consistency}

% We let \( \E_P \) denote
% expectation under \( P \) and use \( \Theta \) to denote the
% collection of all conditional state-occupation probability functions.
Proposition~\ref{prop:stric-prop} can be derived from the fact that the
integrated Brier score (also called the continuous ranked probability score) is
a strictly proper scoring rule \citep{gneiting2007strictly}. This implies that
if we minimise the average loss of the integrated Brier score, we recover the
parameters of the data-generating distribution. Specifically, this implies that
the oracle of a state learner is consistent if the library of learners contains
at least one learner that is consistent for estimation of \( F \). Recall that
the function \(F\) implicitly depends on the data-generating probability measure
\(P\in\mathcal P\) but that this was suppressed in the notation. We now make
this dependence explicit by writing \(F_0\) for the function which is obtained
by substituting a specific \(P_0\in\mathcal{P}\) for \(P\) in equation
\eqref{eq:transition}. In the following we let
\( \mathcal{H}_{\mathcal{P}} = \{F_P : P \in \mathcal{P}\} \) where \( F_P \) is defined as in
equation~(\ref{eq:F-def}) using the measure \( P \in \mathcal{P} \).

\begin{proposition}
  \label{prop:stric-prop}
  If \(P_0\in\mathcal{P}\) then
  \begin{equation*}
    F_0 = \argmin_{F \in \mathcal{H}_{\mathcal{P}}} P_0{[\bar{B}_\tau(F, \blank)]},
  % F^* = \argmin_{(\Lambda_1,\Lambda_2,\Gamma) \in \mathcal{M}_{\tau}\otimes\mathcal{M}_{\tau}\otimes\mathcal{M}_{\tau}} P_0{[\bar B_\tau(\phi_{(\Lambda_1,\Lambda_2,\Gamma)}, \blank)]},
  \end{equation*}
  \( H \)-almost surely for any \( j\in \{-1,0,1,2\} \) and almost any
  \( t \in [0, \tau]\).
\end{proposition}
\begin{proof}
  See Appendix~\ref{sec:proof-proposition}.
\end{proof}

\subsection{Oracle inequalities}
\label{sec:finite-sample-oracle}

We establish a finite sample oracle result for the state learner. Our
Corollary~\ref{cor:oracle-prop} is in essence a special case of
Theorem 2.3 in \citep{vaart2006oracle}.  We assume that we split the
data into equally sized folds, and for simplicity of presentation we
take \( n \) to be such that \( |\data_n^{-k}| = n/K \) with \( K \)
fixed. We will allow the number of learners to grow with \( n \) and
write
\( \mathcal{F}_n=\mathcal{F}(\mathcal{A}_{1,n}, \mathcal{A}_{2,n},
\mathcal{B}_n)\) as short-hand notation and to emphasise the
dependence on \( n \).
% The discrete super $\hat{\phi}_n$ and the
% oracle $\tilde{\phi}_n$ are defined as in Section~\ref{sec:framework}
% but now with respect to the library \( \mathcal{F}_n \) and the loss
% \( B \).
In the following we let the space \( \mathcal{H}_{\mathcal{P}} \) be equipped with the norm
\( \| \blank \|_{P_0} \) defined as
\begin{equation}
  \label{eq:norm}
  \| F \|_{P_0} = 
  \left\{
    \sum_{j=-1}^{2}\int_{\mathcal{X}} \int_0^{\tau} F(t, j, x)^2 \diff t H_0( \diff x)
  \right\}^{1/2}.
\end{equation}

\begin{corollary}
  \label{cor:oracle-prop}
  For all \(P_0\in\mathcal{P}\), \( n \in \N \), \( k \in \{1, \dots, K\} \),
  and $\delta>0$,
  \begin{align*}
    \E_{P_0}{\left[ \Vert \hat{\phi}_n(\data_n^{-k}) - F_0 \Vert_{P_0}^2 \right]}
    & \leq (1 + 2\delta)
      \E_{P_0}{\left[ \Vert \tilde{\phi}_n(\data_n^{-k}) - F_0 \Vert_{P_0}^2 \right]}
    % \\
    % & \quad
      + (1+ \delta) 16   K \tau
      \left(
      13 + \frac{12}{\delta}
      \right)
      \frac{\log(1 + |\mathcal{F}_n|)}{n}.
  \end{align*}
\end{corollary}
\begin{proof}
  See Appendix~\ref{sec:proof-proposition}.
\end{proof}

Corollary~\ref{cor:oracle-prop} has the following asymptotic consequences.

\begin{corollary}
  \label{cor:asymp-cons}
  Assume that \( |\mathcal{F}_n| = \bigO(n^q)\), for some \( q \in \N \)
  and that there exists a sequence \( \phi_n \in \mathcal{F}_n \),
  \( n \in \N \), such that
  \( \E_{P_0}{\left[ \Vert \phi_n(\data_n^{-k}) - F_{0} \Vert_{P_0}^2 \right]} =
  \bigO(n^{-\alpha}) \), for some \( \alpha\leq 1 \).
  \begin{enumerate}
  \item If $\alpha=1$ then
    \( \E_{P_0}{\left[ \Vert \hat{\phi}_n(\data_n^{-k}) - F_0 \Vert_{P_0}^2
      \right]} = \bigO(\log(n)n^{-1}) \).
  \item If $\alpha<1$ then
    \( \E_{P_0}{\left[ \Vert \hat{\phi}_n(\data_n^{-k}) - F_0 \Vert_{P_0}^2 \right]} =
    \bigO(n^{-\alpha}) \).
  \end{enumerate}
\end{corollary}
\begin{proof}
  See Appendix~\ref{sec:proof-proposition}.
\end{proof}


\subsection{Transience of the second order remainder structure}

In this section we demonstrate a theoretical property of the state
learner which is useful for targeted learning (c.f., Section
\ref{sec:targeted-learning}). Specifically we consider an estimator of
a target parameter which is obtained by substituting the state learner
estimates of the nuisance parameters $\Lambda_1$, $\Lambda_2$, and
$\Gamma$. An example is an estimator of the cumulative incidence
curve, which can be obtained from estimators of $\Lambda_1$ and
$\Lambda_2$. Another example is provided in Section \ref{sec:targeted-learning}.
By equations~(\ref{eq:lambdaj}) and~(\ref{eq:gamma}) and the definition of
\( F \), we have
\begin{equation}
  \label{eq:7}
  \Gamma(t , x) 
  = \int_0^t  \frac{F(\diff s, -1, x )}{F(s-, 0, x )},
  \quad \text{and} \quad
  \Lambda_j(t , x) 
  = \int_0^t  \frac{F(\diff s, j, x )}{F(s-, 0, x )},
  \quad j \in \{1,2\},
\end{equation}
and thus an estimator based on \( \hat{\Lambda}_{1,n} \),
\( \hat{\Lambda}_{2,n} \), and \( \hat{\Gamma}_{n} \) can also be obtained from
an estimator of $F$ using equation~(\ref{eq:7}). A so-called targeted estimator
has the key feature that it is asymptotically equivalent to a sum of i.i.d.\
random variables plus a second order remainder term
\citep{van2011targeted,hines2022demystifying}. For the setting with competing
risks, the remainder term is dominated by terms of the form
\begin{equation}
  \label{eq:dr-term}
  P{\left[
      \int_0^{\tau} w_n(s, \blank)
      \hat{M}_{1,n}(s \mid  \blank)
      \hat{M}_{2,n}(\diff s \mid  \blank)
    \right]},
\end{equation}
where \( (\hat{M}_{1,n}, \hat{M}_{2,n}) \) is any of the nine combinations of
\( \hat{M}_{1,n} \in \{[\Gamma -\hat{\Gamma}_n], [\Lambda_1
-\hat{\Lambda}_{1,n}], [\Lambda_2 -\hat{\Lambda}_{2,n}]\} \) and
\( \hat{M}_{2,n} \in \{[\Gamma -\hat{\Gamma}_n], [\Lambda_1
-\hat{\Lambda}_{1,n}], [\Lambda_2 -\hat{\Lambda}_{2,n}]\} \), and \( w_n \) is
some data-dependent function with domain \([0,\tau]\times\mathcal X \)
\citep{van2003unified}. In particular, a targeted estimator will be
asymptotically linear if the `products' of the estimation errors
\( \hat{M}_{1,n} \) and \( \hat{M}_{2,n} \) in equation~(\ref{eq:dr-term}) are
\( \smallO_P{(n^{-1/2})}\). Proposition~\ref{prop:dr-structure} states that if
equation~(\ref{eq:dr-term}) holds for a targeted estimator based on estimators
$\hat{\Lambda}_{1,n}$, $\hat{\Lambda}_{2,n}$, and $\hat{\Gamma}_{n}$, then a
similar product structure holds for a targeted estimator based on
\( \hat{F}_n \). We state the result for the special case that
\(\hat{M}_{1,n}= \Gamma-\hat{\Gamma}_n \) and
\(\hat{M}_{2,n} =\Lambda_1-\hat{\Lambda}_{1,n} \), but similar results hold for
any combinations of \( \Gamma-\hat{\Gamma}_n\),
\( \Lambda_1-\hat{\Lambda}_{1,n} \), and \( \Lambda_2-\hat{\Lambda}_{2,n} \).
\begin{proposition}
  \label{prop:dr-structure}
  Assume that \( w(s,x)\leq c \), \( F(s, 0, x) \geq 1/c \) and
  \( \hat{F}_n(s, 0, x) \geq 1/c \) for some \( c>0 \) for all
  \( s \in [0, \tau] \) and \( x \in \mathcal{X} \). Then there are real-valued
  uniformly bounded functions \( w^a_n \), \( w^b_n \), \( w^c_n \), and
  \( w^d_n \) with domain \( [0,\tau]^2 \times \mathcal{X} \) such that
  \begin{align*}
    & P_0{\left[
      \int_0^{\tau} w(s, \blank)
      \left\{
      \Gamma_0(s,\blank) -\hat{\Gamma}_n(s,\blank)
      \right\}
      [\Lambda_0-\hat{\Lambda}_n]
      (\diff s, \blank)
      \right]}
    \\
    & =
      P_0{\left[
      \int_0^{\tau} \int_0^{s} w^a_n(s,u,\blank) [F_0 - \hat{F}_n](u-, 0, \blank)[F_0 - \hat{F}_n](s-, 0, \blank) F_0(\diff u, 2, \blank ) F_0 ( \diff s, 1, \blank)
      \right]}
    \\
    & \quad +
      P_0{\left[
      \int_0^{\tau} \int_0^{s} w^b_n(s,u,\blank) [F_0 - \hat{F}_n](u-, 0, \blank)
      F_0(\diff u, 2, \blank ) [F_0 - \hat{F}_n](\diff s, 1, \blank)
      \right]}
    \\
    & \quad +
      P_0{\left[
      \int_0^{\tau} \int_0^{s} w^c_n(s,u,\blank) [F_0 - \hat{F}_n](\diff u, 2, \blank)
      [F_0 - \hat{F}_n](s-, 0, \blank)
      F_0(\diff s, 1, \blank ) 
      \right]}
    \\
    & \quad +
      P_0{\left[
      \int_0^{\tau} \int_0^{s} w^d_n(s,u,\blank) [F_0 - \hat{F}_n](\diff u, 2, \blank)
      [F_0 - \hat{F}_n](\diff s, 1, \blank)
      \right]}.
  \end{align*}
\end{proposition}
\begin{proof}
  See Appendix~\ref{sec:state-learner-with}.
\end{proof}

\section{Targeted learning}
\label{sec:targeted-learning}

We are interested in a parameter
\( \theta \colon \mathcal{Q} \rightarrow \Theta \) that expresses a
property of the uncensored population governed by the measure
\( Q \in \mathcal{Q} \). The parameter space $\Theta$ can be a subset
of \(\R^d\) or a subset of a function space, for example a subset of
\(\mathcal{M}_{\tau}\). In subsection~\ref{sec:cause-spec-aver} we
discuss an example from causal inference where $\theta$ is the average
treatment effect and \( \Theta = [-1,1] \).
To discuss the role of the state learner for targeted learning we briefly review
some results from semiparametric efficiency theory. Extensive reviews and
introductions are available elsewhere
\cite[e.g.,][]{pfanzagl1985contributions,bickel1993efficient,van2003unified,tsiatis2007semiparametric,kennedy2016semiparametric}.
Under the assumption of conditional independent censoring and positivity,
$\theta$ is identifiable from \( \mathcal{P} \) which means that there exists an
operator \( \Psi \colon \mathcal{P} \rightarrow \Theta \) such that
\( \theta(Q) = \Psi(P_{Q, \Gamma}) \) for all $\Gamma \in \mathcal{M}_{\tau}$.
By equation~(\ref{eq:parametrizeP}) this implies that we may write
\begin{equation*}
  \theta(Q) = \Psi(P) = \tilde{\Psi}^0(\Lambda_1, \Lambda_2, H),
\end{equation*}
for some operator \( \tilde{\Psi}^0 \). The state learner provides a
ranking of tuples
\( (a_1, a_2, b) \in \mathcal{A}_1 \times \mathcal{A}_2 \times
\mathcal{B} \), and we use \( \hat{a}_{1,n} \), \( \hat{a}_{2,n} \),
and \( \hat{b}_n \) to denote the learners corresponding to the
discrete state learner \( \hat{\phi}_n \). Letting \( H(\data_n) \)
denote the empirical measure of \( \{X_1, \dots, X_n\} \), we obtain a
simple plug-in estimator of $\theta$:
\begin{equation}
  \label{eq:2}
  \hat{\Psi}^0(\data_n) =
  \tilde{\Psi}^0(\hat{a}_{1,n}(\data_n), \hat{a}_{2,n}(\data_n), H(\data_n)). 
\end{equation}

The asymptotic distribution of \( \hat{\Psi}_{\tau, j}^0 \) is
difficult to analyze due to the cross-validated model selection
involved in the estimation of the nuisance parameters $\Lambda_1$ and
$\Lambda_2$. In addition, the estimator will typically have an
asymptotic bias that vanishes at a too slow 
rate. Using tools from semi-parametric efficiency theory, it is
possible to construct a so-called targeted or debiased estimator with
smaller asymptotic bias and a asymptotic distribution which we know
how to estimate
\citep{bickel1993efficient,van2011targeted,chernozhukov2018double}. A
targeted estimator is based on the efficient influence function for
the parameter $\tilde{\Psi}^0$ and relies on an estimator of $\Gamma$
in addition to estimators of \( \Lambda_1 \) and $\Lambda_2$. The
efficient influence function is a \( P \)-zero mean and square
integrable function indexed by the nuisance parameters
\( (\Lambda_1, \Lambda_2, \Gamma) \), which we denote by
\( \psi(\blank ; \Lambda_1, \Lambda_2, \Gamma) \). The name is
justified because any regular asymptotically linear estimator that has
\( \psi \) as its influence function is asymptotically efficient,
meaning that it has smallest asymptotic variance among all regular
asymptotically linear estimators.

An example of a targeted estimator is the one-step estimator, defined as
\begin{equation}
    \label{eq:one-step-def}
    \hat{\Psi}_{\text{OS}}(\data_n)
    =
    \tilde{\Psi}^0(\hat{a}_{1,n}(\data_n), \hat{a}_{2,n}(\data_n),
    H(\data_n))
    + \empmeas{[\psi(\blank; \hat{a}_{1,n}(\data_n), \hat{a}_{2,n}(\data_n),
      \hat{b}_n(\data_n) )]},
\end{equation}
where \( \empmeas \) is the empirical measure of a data set
\(\{O_i\}_{i=1}^n\).
Under suitable regularity conditions
we have the
following asymptotic expansion of the one-step estimator
\citep{pfanzagl1985contributions,van2003unified,fisher2021visually,kennedy2022semiparametric},
\begin{equation*}
  \hat{\Psi}_{\text{OS}}(\data_n)- \Psi(P)
  =  \empmeas{[\psi(\blank ; \Lambda_1, \Lambda_2, \Gamma)]}
  +\mathrm{Rem}{(\hat{\Lambda}_{1,n},\hat{\Lambda}_{2,n},  \hat{\Gamma}_n, P)} + \smallO_{P}(n^{-1/2}),
\end{equation*}
where the remainder term has the form
\begin{equation}
  \label{eq:4}
  \mathrm{Rem}{(\hat{\Lambda}_{1,n},\hat{\Lambda}_{2,n},  \hat{\Gamma}_n, P)}
  = \mathcal{O}_P{
    \left\{
      \|\Lambda_1-\hat{\Lambda}_{1,n}\|^2
      +
      \|\Lambda_2-\hat{\Lambda}_{2,n}\|^2
      +
      \|\Gamma-\hat{\Gamma}_{n}\|^2
    \right\}
  },
\end{equation}
for some suitable norm \( \|\blank \| \), for instance the
\( \mathcal{L}_{P}^2 \)-norm. When equation~(\ref{eq:4}) holds and the
nuisance parameters $\Lambda_1$, $\Lambda_2$, and $\Gamma$ are
consistently estimated at rate \( \smallO_P{(n^{-1/4})} \), then
\begin{equation}
  \label{eq:3}
  \sqrt{n}(\hat{\Psi}_{\text{OS}}(\data_n)- \Psi(P)) \weakly \mathcal{N}(0,
  P{[\psi(\blank; \Lambda_1, \Lambda_2, \Gamma)^2]}),
\end{equation}
where we use \( \weakly \) to denote weak convergence \citep{van2000asymptotic}.
In particular, equation~(\ref{eq:3}) and Slutsky's lemma imply that we can
obtain asymptotically valid \((1-\alpha)\cdot100\%\) confidence intervals by
calculating
\begin{equation*}
  \left[
    \hat{\Psi}_{\text{OS}}(\data_n) - q_{\alpha/2} \hat{\sigma}(\data_n) ,
    \;
    \hat{\Psi}_{\text{OS}}(\data_n) + q_{\alpha/2} \hat{\sigma}(\data_n)
  \right],
\end{equation*}
where \( q_{\alpha} \) is the \( (1-\alpha) \)-quantile of the standard normal
distribution and
\( \hat{\sigma}(\data_n)^2 = \empmeas{ \left[ \psi(\blank;
    \hat{a}_{1,n}(\data_n), \hat{a}_{2,n}(\data_n), \hat{b}_n(\data_n))^2
  \right]} \).


\subsection{Average treatment effect on the absolute risk of an event}
\label{sec:cause-spec-aver}

In the following we demonstrate how the state learner and the general
estimation strategy outlined above can be used to construct an
estimator of the cause-specific average treatment effect. We assume
that the covariate vector \( X \in \R^p \) contains a binary treatment
indicator \( A \) and a vector of potential confounders,
\( W \in \mathcal{W}\subset \R^{p-1} \).
We use $\mu$
to denote the marginal distribution of \( W \) and $\pi$ to denote the
conditional probability of treatment,
\begin{equation*}
  \pi(w) = P(A=1 \mid W=w).
\end{equation*}
We assume throughout that $\pi$ is uniformly bounded away from \( 0 \)
and \( 1 \) on \( \mathcal{W} \) and that both \( A \) and \( W \) are
fully observed for all individuals. We use a super learner to
estimate $\pi$ \citep{Polley_Ledell_Kennedy_Laan_2023_Superlearn}, and
we denote this estimator by $\hat{\pi}_n$. We use the empirical
measure of \( \{W_1, \dots, W_n\} \) to estimate $\mu$, and denote
this estimator by $\hat{\mu}_n$. As parameter of interest we consider
the standardised difference in the absolute risk of an event with
cause 1 at time $\tau$:
\begin{equation*}
  \theta_{{\tau}}(Q) = \int_{\mathcal{W}} 
  \left\{
    \int_0^{\tau}
    S(s- \mid w, 1)  \Lambda_1(\diff s \mid w, 1)
    -
    \int_0^{\tau}
    S(s- \mid w, 0)  \Lambda_1(\diff s \mid w, 0)
  \right\}
  \mu(\diff w).
\end{equation*}
Under the usual assumptions for causal inference (consistency,
positivity, no unmeasured confounding) \( \theta_{{\tau}} \) can be
given the causal interpretation
\begin{equation*}
  \theta_{{\tau}}(Q) =
  P{(T^{1} \leq \tau, D^{1}=1)}-
  P{(T^{0} \leq \tau, D^{0}=1)},
\end{equation*}
where \( (T^a, D^a) \), \( a \in \{0,1\} \), denotes potential outcomes
\citep{hernanRobinsWhatIf}. In this case, the interpretation of $\theta_{\tau}$
is the difference in the average risk of cause \( 1 \) occurring before time
\( \tau \) in the population if everyone had been given treatment (\( A=1 \))
compared to if no one had been given treatment \( (A=0) \).

Using equation~(\ref{eq:surv-def}) we may write
\( \theta_{{\tau}}(Q) = \tilde{\Psi}_{t}^0(\Lambda_1, \Lambda_2, \mu) \), where
\begin{equation}
  \label{eq:1}    
  \begin{split}
  \tilde{\Psi}_{t}^0(\Lambda_1, \Lambda_2, \mu) & =
  \int_{\mathcal{W}} 
  \int_0^{\tau}
  e^{-\Lambda_1(s- \mid w, 1)-\Lambda_2(s- \mid w, 1)}  \Lambda_1(\diff s \mid
  w, 1)
  \mu(\diff w)
  \\
  &  \quad
  -\int_{\mathcal{W}} 
  \int_0^{\tau}
  e^{-\Lambda_1(s- \mid w, 0)-\Lambda_2(s- \mid w, 0)}  \Lambda_1(\diff s \mid w, 0)
  \mu(\diff w).
  \end{split}
\end{equation}
The efficient influence function for the parameter $\tilde{\Psi}_{\tau}$ depends
on the set \( (\Lambda_1, \Lambda_2, \Gamma, \pi) \) of nuisance parameters.
We define
\begin{align*}
  \omega_a(A,W; \pi)
  &=  \frac{% (-1)^{a+1}
    \1{\{A=a\}}}{\pi(W)^{a}(1-\pi(W))^{1-a}},
  \\
  g(t, A, W; \Lambda_1, \Lambda_2)
  & = \int_0^{t}
    e^{-\Lambda_1(s- \mid W, A)-\Lambda_2(s- \mid W, A)}  \Lambda_1(\diff s \mid
    W, A),
  \\  
  M_j(\diff t \mid A, W;  \Lambda_j  )
  & = N_j(\diff t) -
    \1{\{\tilde{T} \geq t\}} \Lambda_j(\diff t \mid W, A),
    \quad j \in \{1,2\},
  \intertext{and}
  M(\diff t \mid A, W;  \Lambda_1, \Lambda_2  )
  & = M_1(\diff t \mid A, W;  \Lambda_1  ) +
    M_2(\diff t \mid A, W;  \Lambda_2  ).
\end{align*}
The efficient influence function can now be written as
\citep{van2003unified,jewell2007non,rytgaard2022targeted},
\begin{equation*}
  \psi_{\tau}(O; \Lambda_1, \Lambda_2, \Gamma, \pi)
  = \psi_{\tau}^1(O; \Lambda_1, \Lambda_2, \Gamma, \pi)
  - \psi_{\tau}^0(O; \Lambda_1, \Lambda_2, \Gamma, \pi)
  -\tilde{\Psi}_{t}^0(\Lambda_1, \Lambda_2, \mu),
\end{equation*}
where
\begin{equation}
  \label{eq:5}
  \begin{split}
    & \psi_{\tau}^a(O; \Lambda_1, \Lambda_2, \Gamma, \pi)
    \\
    & =
      \omega_a(A,W; \pi)
      \int_0^{\tau} e^{\Gamma(t- \mid A, W)}   
      M_1(\diff t \mid A, W; \Lambda_1)
    \\
    & \quad
      -
      \omega_a(A,W; \pi)
      g(\tau, A, W; \Lambda_1, \Lambda_2)
      \int_0^{\tau}
      e^{[\Gamma+\Lambda_1 + \Lambda_2](t- \mid A, W)}
      M(\diff t \mid A, W; \Lambda_1, \Lambda_2)
    \\
    & \quad
      +
      \omega_a(A,W; \pi)      
      \int_0^{\tau}
      g(t, A, W; \Lambda_1, \Lambda_2)
      e^{[\Gamma+\Lambda_1 + \Lambda_2](t- \mid A, W)}
      M(\diff t \mid A, W; \Lambda_1, \Lambda_2)
    \\
    & \quad + g(\tau, a, W; \Lambda_1, \Lambda_2).
  \end{split}
\end{equation}
Equations~(\ref{eq:1}) and~(\ref{eq:5}) allow us to construct a one-step
estimator by using the definition given in equation~(\ref{eq:one-step-def}),
which gives the estimator
\begin{equation}
  \label{eq:one-step-comp-ate}
  \begin{split}
    \hat{\Psi}_{t,\text{OS}}(\data_n)
    = &
        \tilde{\Psi}_{t}^0(\hat{a}_1(\data_n), \hat{a}_2(\data_n),
        \hat{\mu}_n(\data_n))
    \\
      &
        +
        \empmeas{[\psi_{\tau}(\blank; \hat{a}_{1,n}(\data_n), \hat{a}_{2,n}(\data_n),
        \hat{b}_n(\data_n), \hat{\pi}_n(\data_n))]}
    \\
    = &
        \empmeas{[\psi_{\tau}^1(\blank; \hat{a}_{1,n}(\data_n), \hat{a}_{2,n}(\data_n),
        \hat{b}_n(\data_n), \hat{\pi}_n(\data_n))]}
    \\
      &
        - \empmeas{[\psi_{\tau}^0(\blank; \hat{a}_{1,n}(\data_n), \hat{a}_{2,n}(\data_n),
        \hat{b}_n(\data_n), \hat{\pi}_n(\data_n))]}.
  \end{split}
\end{equation}


\section{Numerical experiments}
\label{sec:numer-exper}


In this section we report results from a simulation study. In the first part we
consider estimation of the conditional survival function. Here we compare the
state learner to two IPCW based discrete super learners that use either the
Kaplan-Meier estimator or a Cox model to estimate the censoring probability
\citep{gonzalez2021stacked}. In the second part we compare the state learner to
the super learner proposed by \cite{westling2021inference}.

In both parts we use the same data-generating mechanism. We generate
data according to a distribution motivated from a real dataset in
which censoring depends on the baseline covariates. We simulate data
based on a prostate cancer study described in
\citep{kattan2000pretreatment}. The outcome of interest was the time
to tumor recurrence, and five baseline covariates were used to predict
outcome: prostate-specific antigen (PSA, ng/mL), Gleason score sum
(GSS, values between 6 and 10), radiation dose (RD), hormone therapy
(HT, yes/no) and clinical stage (CS, six values). The study was
designed such that a patient's radiation dose depended on when the
patient entered the study \citep{gerds2013estimating}. This in turn
implied that the time of censoring depended on the radiation dose. The
data were re-analyzed in \citep{gerds2013estimating} where a
sensitivity analysis was conducted based on simulated data. We use the
same simulation setup, where event and censoring times are generated
according to parametric Cox-Weibull models estimated from the original
data, and the covariates are generated according to either marginal
Gaussian normal or binomial distributions estimated from the original
data \citep[c.f.,][Section~4.6]{gerds2013estimating}. We refer to this
simulation setting as ``dependent censoring''. We also considered a
simulation setting where data were generated in the same way, except
that censoring was generated completely independently. We refer to
this simulation setting as ``independent censoring''.

For all super learners we use a library consisting of three learners: The
Kaplan-Meier estimator \citep{kaplan1958nonparametric,Gerds_2019prodlim}, a Cox
model with main effects \citep{cox1972regression, survival-package}, and a
random survival forest \citep{ishwaran2008random,rfsrc-paclage}. We use the same
library to learn the outcome and the censoring mechanism. To be precise, note
that given a learner for the cumulative hazard function of the outcome event, we
can typically use the same method to construct a learner of the cumulative
hazard function of the censoring distribution. This works by training the
learner on the data set \( \data_n^c \), where
\( \data_n^c = \{O_i^c\}_{i=1}^n \) with
\( O_i^c = (\tilde{T}_i, 1-\Delta, X_i) \). When we say that we use a learner
for the cumulative hazard function of the outcome to learn the cumulative hazard
function of the censoring time, we mean that the learner is trained on
\( \data_n^c \).

We compare the state learner to two IPCW based super learners: The
first super learner, called IPCW(Cox), uses a Cox model with main
effects to estimate the censoring probabilities, while the second
super learner, called IPCW(KM), uses the Kaplan-Meier estimator to
estimate the censoring probabilities. The Cox model for the censoring
distribution is correctly specified in both simulation settings while
the Kaplan Meier estimator only estimates the censoring model
correctly in the simulation setting where censoring is
independent. Both IPCW super learners are fitted using the
\texttt{R}-package \texttt{riskRegression}
\citep{Gerds_Ohlendorff_Ozenne_2023}.
%
% | time | sim_setting | true_events | true_cens | at_risk |
% |------+-------------+-------------+-----------+---------|
% |   36 | original    |      24.619 |    61.853 |  25.774 |
% |   36 | indep_cens  |      24.674 |    38.740 |  46.141 |
%
The IPCW super learners use the integrated Brier score up to a fixed time
horizon (36 months). The marginal risk of the event before this time horizon is
\(\approx 24.6\)\%. Under the ``dependent censoring'' setting the marginal
censoring probability before the time horizon is \(\approx 61.9\)\%. Under the
``independent censoring'' setting the marginal censoring probability before this
time horizon is \( \approx 38.7 \)\%.

Each super learner provides a learner for the cumulative hazard function for the
outcome of interest. From the cumulative hazard function a risk prediction model
can be obtained (c.f., equation~(\ref{eq:surv-def}) with $\Lambda_2 = 0$). We
measure the performance of each super learner by calculating the index of
prediction accuracy (IPA) \citep{kattan2018index} at a fixed time horizon (36
months) for the risk prediction model provided by the super learner. The IPA is
1 minus the ratio between the model's Brier score and the null model's Brier
score, where the null model is the model that does not use any covariate
information. The IPA is approximated using a large (\( n = 20,000 \))
independent data set of uncensored data. As a benchmark we calculate the
performance of the risk prediction model chosen by the oracle selector, which
uses the large data set of uncensored event times to select the learner with the
highest IPA.

The results are shown in Figure~\ref{fig:ipcw-fail}. We see that in
the scenario where censoring depends on the covariates, using the
Kaplan-Meier estimator to estimate the censoring probabilities
provides a risk prediction model with an IPA that is lower than the
risk prediction model provided by the state learner. The performance
of the risk prediction model selected by the state learner is similar
to the risk prediction model selected by the IPCW(Cox) super learner
which a priori uses a correctly specified model for the censoring
distribution. Both these risk prediction models are close to the
performance of the oracle, except for small sample sizes.

\begin{figure}
  \centering %
  \includeFigCond[width=.8\linewidth]{experiment-fig-sl-ipcw.pdf}
  \caption[]{For the risk prediction models provided by each of the super
    learners, the IPA is plotted against sample size. The results are averages across 
    1000 simulated data sets and the error bars are used to quantify the Monte Carlo
    uncertainty.
  }
  \label{fig:ipcw-fail}
\end{figure}

We next compare the state learner to the super learner \texttt{survSL}
\citep{westling2021inference}. This is another super learner which
like the state learner works without a pre-specified censoring
model. Note that both the state learner and \texttt{survSL} provide a
prediction model for the event time outcome and also for the
probability of being censored. Hence, we compare the performance of
these methods with respect to both the outcome and the censoring
distribution. Again we use the IPA to quantify the predictive
performance.

The results are shown in Figures~\ref{fig:zelefski-out}
and~\ref{fig:zelefski-cens}. We see that for most sample sizes, the state
learner selected prediction models for both censoring and outcome which have
similar or higher IPA compared to the prediction models selected by
\texttt{survSL}.
\begin{figure}
  \centering %
  \includeFigCond[width=.8\linewidth]{experiment-fig-sl-survSL-out.pdf}
  \caption[]{For the risk prediction models of the outcome provided by each
    of the super learners, the IPA at the fixed time horizon is plotted against
    sample size. The results are averages across 1000 repetitions and the error
    bars are used to quantify the Monte Carlo uncertainty.}
  \label{fig:zelefski-out}
\end{figure}

\begin{figure}
  \centering %
  \includeFigCond[width=.5\linewidth]{experiment-fig-sl-survSL-cens.pdf}
  \caption[]{For the risk prediction models of the censoring model provided by
    each of the super learners, the IPA at the fixed time horizon is plotted
    against sample size. The results are averages across 1000 repetitions and
    the error bars are used to quantify the Monte Carlo uncertainty.}
  \label{fig:zelefski-cens}
\end{figure}


\section{Prostate cancer study}
\label{sec:real-data-appl}

In this section we use the prostate cancer data of
\cite{kattan2000pretreatment} to illustrate the use of the state
learner in the presence of competing risks. We have introduced the
data in Section~\ref{sec:numer-exper}. The data consists of 1,042
patients who are followed from start of followup until tumor
recurrence, death without tumor recurrence or end of followup
(censored) whatever came first. For the sole purpose of illustration,
we estimate the average treatment effect of hormone therapy on death
and tumor recurrence. To do this we adapt the estimation strategy of
Section~\ref{sec:targeted-learning} as follows.  We use the state
learner to rank libraries of learners for the cause-specific
cumulative hazard functions of tumor recurrence, death without tumor
recurrence, and censoring.  The libraries of learners include the five
learners described in Table~\ref{tab:zel-library}.  We use the same
set of learners to learn the cumulative hazard function of tumor
recurrence \( \Lambda_1 \), the cumulative hazard function of death
without tumor recurrence \( \Lambda_2 \), and the cumulative hazard
function of the conditional censoring distribution $\Gamma$. 
We then use the highest ranked combination
of learners and apply formula~\eqref{eq:one-step-comp-ate}.


\begin{table}
  \caption{\label{tab:zel-library}Overview of the five learners used by the
    state learner when applied to the prostate cancer data set. The Kaplan-Meier
    estimator was fitted using the package \texttt{prodlim}
    \citep{Gerds_2019prodlim}. All Cox models included all five covariates in
    the model and were fitted using the package \texttt{survival}
    \citep{survival-package}. All penalised Cox models included all five
    covariates as linear predictors and were fitted using the package
    \texttt{glmnet} \citep{glmnet-cox,glmnet-glm}. The random forest was fitted
    with the package \texttt{randomForestSRC} \citep{rfsrc-paclage}.}
  \centering
  \begin{tabular}{lll}
    \toprule
    Family & Model & Description \\
    \midrule
    Marginal & \texttt{KM} & The Kaplan-Meier estimator \\ 
    Cox & \texttt{Cox} & All five covariates included with additive effects \\
           & \( \texttt{Cox strata CS} \)  & Cox model stratified on CS  \\
           % & \( \texttt{Cox strata HT} \)  & Cox model stratified on HT \\
           % & \( \texttt{Cox spline} \)  & PSA and RD modeled with splines \\ 
    Penalised Cox & \texttt{Lasso} & Cox model with \( L_1 \)-norm penalty   \\
           % & \texttt{Ridge} & Cox model with \( L_2 \)-norm penalty \\
           & \texttt{Elastic} & Cox model with \( L_1 \)- and \( L_2 \)-norm penalty \\
    Random forest & \texttt{RF} & Random forest with default settings \\
    \bottomrule 
  \end{tabular}
\end{table}

This gives a library consisting of \( 5^3 = 125 \) learners for the conditional
state occupation probability function \( F \) defined in
equation~(\ref{eq:F-def}). We use five folds for training and testing the
models, and we repeat training and evaluation five times with different splits.
The integrated Brier score (defined in Section~\ref{sec:super-learner-simple})
for all learners are shown in Figure~\ref{fig:zelefski-real}, and the top 10
combinations of learners are displayed in Table~\ref{tab:zelefski-real}. We see
that the prediction performance is mostly affected by the choice of learner for
the censoring distribution. Several combinations of learners give similar
performance as measured by the integrated Brier score, as long as a random
forest is used to model the censoring distribution.

\begin{figure}
  \centering %
  \includeFigCond[width=.9\linewidth]{real-data-state-learner.pdf}
  \caption[]{The results of applying the 125 combinations of learners to the
    prostate cancer data set. The learners are \texttt{KM} (KM), \texttt{Cox
      strata CS} (strata), \texttt{Lasso} (lasso), \texttt{Elastic} (elastic),
    and \texttt{RF} (RF) as described Table~\ref{tab:zel-library}. The error
    bars are based on five repetitions using different splits. We refer to
    learners of \( \Lambda_1 \), \( \Lambda_2 \), and $\Gamma$ as `Tumor
    learner', `Death learner', and `Censoring learner', respectively.}
  \label{fig:zelefski-real}
\end{figure}


\begin{table}
  \caption{\label{tab:zelefski-real}The 10 best performing models in terms of integrated Brier score. The
    reported standard errors are based on five repetitions using different
    splits. The models are described in Table~\ref{tab:zel-library}. We refer to
    learners of \( \Lambda_1 \), \( \Lambda_2 \), and $\Gamma$ as `Tumor
    learner', `Death learner', and `Censoring learner', respectively.}
  \centering
  \input{./real-data-tab.tex}
\end{table}


We use the learners of the three cumulative hazard functions
selected by the state learner and the estimator defined in
Section~\ref{sec:cause-spec-aver}, equation~(\ref{eq:one-step-comp-ate}), to
estimate the average treatment effect of hormone therapy on risk of tumor
recurrence and death. The propensity score is estimated with a lasso model that
includes all levels of interaction. The results are shown in
Figure~\ref{fig:zelefski-real-target} for 6 month intervals after baseline with
point wise 95\% confidence intervals. We see that hormone therapy appears to
decrease the risk of tumor recurrence and increase the risk of death without
tumor recurrence, but that none of the estimated effects are statistically
significant from zero.

\begin{figure}
  \centering%
  \includeFigCond[width=.8\linewidth]{real-data-target.pdf}
  \caption[]{Estimates of the average treatment effect of hormone therapy on the
    risk of tumor recurrence and death obtained from the prostate cancer study
    analyzed by \cite{kattan2000pretreatment}. The estimates are based on the
    estimator defined in equation~(\ref{eq:one-step-comp-ate}) with point wise
    95\% confidence intervals calculated as described in
    Section~\ref{sec:targeted-learning}. The estimates of the nuisance
    parameters are provided by the state learner.}
  \label{fig:zelefski-real-target}
\end{figure}



\section{Discussion}
\label{sec:discussion}

We have proposed a new super learner that can be used with
right-censored data and competing events. Compared to existing
IPCW-based methods, the advantage of the state learner is that it does
not depend on a pre-specified estimator of the censoring distribution,
but selects one automatically based on a library of learners for the
censoring distribution. Furthermore, the state learner neither
requires that \( \Lambda_j \) can be written as an integral with
respect to Lebesgue measure, nor assumes a (semi-)parametric form for
$\Lambda_j$. In the remainder of this section we point to some
limitations of our proposal and discuss avenues for further research.

A major advantage of the state learner is that the performance of each
combination of learners can be estimated without (semi)parametric
assumptions or additional nuisance parameters. The drawback with this
approach is that we are rarely interested in features of the observed
data distribution when the data are right-censored: we are only
interested in the uncensored event time distribution. The finite
sample oracle inequality in Corollary~\ref{cor:oracle-prop} concerns
the function \( F \), which is a feature of \( P \in \mathcal{P} \),
while what we are typically interested in is \( \Lambda_j \) or
\( S \), which are features of \( Q \in \mathcal{Q} \). We emphasise
that while the state learner provides us with estimates of
\( \Lambda_j \) and $\Gamma$ based on libraries \( \mathcal{A}_j \)
and \( \mathcal{B} \), the performance of these learners is not
assessed directly for their respective target parameters, but only
indirectly via the performance of \( F \).
For settings without competing risks, our numerical studies suggest
that measuring the performance of \( F \) also leads to good
performance for estimation of \( S \).
% In the context of targeted learning, a drawback of the state learner is that the
% doubly robustness property defined in equation~(\ref{eq:dr-property}) seem to be
% lost because we only use a single nuisance parameter estimator. As defined here,
% however, the state learner is build using libraries for the conditional
% cause-specific cumulative hazard functions, so some doubly robustness might be
% preserved.

Our proposed super learner can be implemented with a broad library of learners
and using existing software.
% For instance the \texttt{R}-package
% \texttt{riskRegression} \citep{Gerds_Ohlendorff_Ozenne_2023} and the \texttt{R}-package by westling
Furthermore, while
the library \( \mathcal{F}(\mathcal{A}_1,\mathcal{A}_2,\mathcal{B}) \) consists
of \( |\mathcal{A}_1||\mathcal{A}_2||\mathcal{B}| \) many learners, we only need to fit
\( |\mathcal{A}_1| +|\mathcal{A}_2| + |\mathcal{B}| \) many learners in each fold. To
evaluate the performance of each learner we need to perform
\( |\mathcal{A}_1||\mathcal{A}_2||\mathcal{B}| \) many operations to calculate the
integrated Brier score in each hold-out sample, one for each combination of the
fitted models, but these operations are often negligible compared to fitting the
models. Hence the state learner is essentially not more computationally demanding
than any procedure that uses super learning to learn $\Lambda_1$, $\Lambda_2$,
and $\Gamma$ separately. While our proposal is based on constructing the library
\( \mathcal{F} \) from libraries for learning \( \Lambda_1 \), $\Lambda_2$, and
$\Gamma$, it could also be of interest to consider learners that estimate
\( F \) directly.

In our numerical studies, we only considered learners of $\Lambda_j$ and
$\Gamma$ that provide cumulative hazard functions which are piece-wise constant
in the time argument. This simplifies the calculation of \( F \) as the
integrals in equation~(\ref{eq:transition}) reduce to sums. When $\Lambda_j$ or
\( \Gamma \) are absolutely continuous in the time argument, calculating \( F \)
is more involved, but we expect that a good approximation can be achieved by
discretisation. 



\begin{appendices}

\section{Theoretical guarantees for the state learner}
\label{sec:proof-proposition}

In this section we provide proofs of the results stated in
Section~\ref{sec:theor-results-prop}.

Define
\( \bar{B}_{\tau,0}(F, o) = \bar{B}_{\tau}(F, o) - \bar{B}_{\tau}(F_0, o) \) and
\( R_{0}(F) = P_0{[\bar{B}_{\tau,0}(F, \blank)]} \).
\begin{lemma}
  \label{lemma:norm}
  \( R_{0}(F) = \Vert F - F_0 \Vert_{P_0}^2 \), where \( \Vert \blank \Vert_{P_0}\) is defined
  in equation~(\ref{eq:norm}).
\end{lemma}
\begin{proof}
  For any \( t \in [0, \tau] \) and \( j\in \{-1,0,1,2\} \) we have
  \begin{align*}
    & \E_{P_0}{\left[ (F(t, j, X) - \1{\{\eta(t) = j \}})^2 \right]}
    \\
    & =    \E_{P_0}{\left[ (F(t, j, X) - F_0(t, j, X) + F_0(t, j, X) - \1{\{\eta(t) = j
      \}})^2 \right]}
    \\
    & =    \E_{P_0}{\left[ (F(t, j, X) - F_0(t, j, X))^2\right]}
      + \E_{P_0}{\left[ (F_0(t, j, X) - \1{\{\eta(t) = j \}})^2\right]}
    \\
    & \quad
      + 2\E_{P_0}{\left[ (F(t, j, X) - F_0(t, j, X))(F_0(t, j, X) - \1{\{\eta(t) = j
      \}})\right]}
    \\
    & =    \E_{P_0}{\left[ (F(t, j, X) - F_0(t, j, X))^2\right]}
      + \E_{P_0}{\left[ (F_0(t, j, X) - \1{\{\eta(t) = j \}})^2\right]},
  \end{align*}
  where the last equality follows from the tower property. Hence, using Fubini,
  we have
  \begin{equation*}
    P{[\bar{B}_{\tau}(F, \blank)]}
    = \Vert F - F_0 \Vert_{P_0}^2 + P_0{[\bar{B}_{\tau}(F_0, \blank)]}.
  \end{equation*}
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:stric-prop}.]
  The result follows from Lemma~\ref{lemma:norm}.
\end{proof}

Recall that $\mathcal{H}_{\mathcal{P}}$ denote the function space consisting of
all conditional state occupation probability functions for some measure
\( P \in \mathcal{P} \).

\begin{proof}[Proof of Corollary~\ref{cor:oracle-prop}.]
  First note that minimising the loss \( \bar{B}_{\tau} \) is equivalent to
  minimising the loss \( \bar{B}_{\tau,0} \), so the discrete super learner and
  oracle according to \( \bar{B}_{\tau} \) and \( \bar{B}_{\tau,0} \) are
  identical. By Lemma~\ref{lemma:norm}, \( R_0(F) \geq 0 \) for any
  \( F \in \mathcal{H}_{\mathcal{P}} \), and so using Theorem 2.3 from \citep{vaart2006oracle} with
  \( p=1 \), we have that for all \( \delta >0 \),
\begin{align*}
  \E_{P_0}{\left[ R_0(\hat{\phi}_n(\data_n^{-k})) \right]}
  \leq
  &(1+2\delta)\E_{P_0}{\left[ R_0(\tilde{\phi}_n(\data_n^{-k})) \right]}
  \\
  & \quad + (1+\delta) \frac{16 K}{n}
    \log(1 + |\mathcal{F}_n|)\sup_{F \in \mathcal{H}_{\mathcal{P}}}
    \left\{
    M(F) + \frac{v(F)}{R_0(F)}
    \left(
    \frac{1}{\delta} + 1
    \right)
    \right\}
\end{align*}
where for each \( F \in \mathcal{H}_{\mathcal{P}} \), \( (M(F), v(F)) \) is some Bernstein pair for
the function \(o \mapsto \bar{B}_{\tau,0}(F, o) \). As
\( \bar{B}_{\tau,0}(F, \blank) \) is uniformly bounded by \( \tau \) for any
\( F \in \mathcal{H}_{\mathcal{P}} \), it follows from section 8.1 in \citep{vaart2006oracle} that
\( (\tau, 1.5 P_0{[\bar{B}_{\tau,0}(F, \blank)^2]}) \) is a Bernstein pair for
\( \bar{B}_{\tau,0}(F, \blank) \). Now, for any \( a,b,c \in \R \) we have
\begin{align*}
  (a-c)^2 - (b-c)^2
  & = (a-b+b-c)^2 - (b-c)^2
  \\
  & = (a-b)^2 + (b-c)^2 +2(b-c)(a-b) - (b-c)^2
  \\
  & = (a-b)
    \left\{
    (a-b) +  2(b-c)
    \right\}
  \\
  & = (a-b)
    \left\{
     a + b -2c
    \right\},
\end{align*}
so using this with \( a=F(t, j, x) \), \( b=F_0(t, j, x) \), and
\( c = \1{\{\eta(t) = j\}} \), we have by Jensen's inequality
\begin{align*}
  & P_0{[\bar{B}_{\tau,0}(F, \blank)^2]}
  \\
  & \leq
    2\tau\E_{P_0}{\left[
    \sum_{j=-1}^{2} \int_0^{\tau}
    \left\{
    \left(
    F(t, j, X) - \1{\{\eta(t) = j\}}
    \right)^2
    -
    \left(
    F_0(t, j, X) - \1{\{\eta(t) = j\}}
    \right)^2
    \right\}^2
    \diff t 
    \right]}
  \\
  & =2\tau
    \E_{P_0}\Bigg[
    \sum_{j=-1}^{2} \int_0^{\tau}
    \left(
    F(t, j, X) - F_0(t, j, X)
    \right)^2
  \\
  & \quad \quad \quad\quad \quad \quad \times
    \left\{
    F(t, j, X) +  F_0(t, j, X)-2 \1{\{\eta(t) = j\}}
    \right\}^2
    \diff t 
    \Bigg]
  \\
  & \leq
    8\tau \E_{P_0}{\left[
    \sum_{j=-1}^{2} \int_0^{\tau}
    \left(
    F(t, j, X) - F_0(t, j, X)
    \right)^2
    \diff t 
    \right]}.
  \\
  & =
    8\tau \Vert F - F_0 \Vert_{P_0}^2.
\end{align*}
Thus when \( v(F) = 1.5 P_0{[\bar{B}_{\tau,0}(F, \blank)^2]} \) we have by
Lemma~\ref{lemma:norm}
\begin{equation*}
  \frac{v(F)}{R_0(F)}
  = 1.5 \frac{P_0{[\bar{B}_{\tau,0}(F, \blank)^2]}}{P_0{[\bar{B}_{\tau,0}(F, \blank)]}}
  \leq 12 \tau,
\end{equation*}
and so using the Bernstein pairs \( (\tau, 1.5 P_0{[\bar{B}_{\tau,0}(F, \blank)^2]}) \) we have
\begin{equation*}
  \sup_{F \in \mathcal{H}_{\mathcal{P}}}
  \left\{
    M(F) + \frac{v(F)}{R_0(F)}
    \left(
      \frac{1}{\delta} + 1
    \right)
  \right\}
  \leq \tau
  \left(
    13 + \frac{12}{\delta}
  \right),
\end{equation*}
For all $\delta>0$ we thus have
\begin{align*}
  \E_{P_0}{\left[ R_0(\hat{\phi}_n(\data_n^{-k})) \right]}
  \leq
  &(1+2\delta)\E_{P_0}{\left[ R_0(\tilde{\phi}_n(\data_n^{-k})) \right]}
  \\
  & \quad
    + (1+\delta)\log(1 + |\mathcal{F}_n|) \tau \frac{16 K}{n}
    \left(
    13 + \frac{12}{\delta}
    \right),
\end{align*}
and then the final result follows from Lemma~\ref{lemma:norm}.
\end{proof}

\begin{proof}[Proof of Corollary~\ref{cor:asymp-cons}.]
  By definition of the oracle and Lemma~\ref{lemma:norm},
  \begin{equation*}
    \E_{P_0}{\left[ \Vert \tilde{\phi}_n(\data_n^{-k}) - F_0 \Vert_{P_0}^2
      \right]} \leq \E_{P_0}{\left[ \Vert \phi_n(\data_n^{-k}) - F_0 \Vert_{P_0}^2
      \right]}  
  \end{equation*}
  for all \( n \in \N \). The results then follows from
  Corollary~\ref{cor:oracle-prop}.
\end{proof}


\section{The state learner with targeted learning}
\label{sec:state-learner-with}

In this section show that a product structure is preserved when an estimator
$\bar\Psi(\hat{F}_n, \hat{H}_n)$ is used instead of
$\tilde\Psi(\hat{\Lambda}_n, \hat{\Gamma}_n, \hat{H}_n)$.


\begin{proof}[Proof of Proposition~\ref{prop:dr-structure}.]
  For notational convenience we suppress \( X \) in the following. The final
  result can be obtained by adding the argument \( X \) to all functions and
  averaging. We use the relations from equation~(\ref{eq:7}) to write
  \begin{align*}
    & \int_0^{\tau} w(s) 
      \left\{
      \Gamma(s) - \hat{\Gamma}_n(s)
      \right\}
      [\Lambda - \hat{\Lambda}_n](\diff s)
    \\
    & =
      \int_0^{\tau} w(s) 
      \left\{
      \int_0^s \frac{F(\diff u, 2)}{F(u-, 0)} -
      \int_0^s \frac{\hat{F}_n(\diff u, 2)}{\hat{F}_n(u-, 0)}  -
      \right\}
      \left[
      \frac{F(\diff s, 1)}{F(s-, 0)}
      - \frac{\hat{F}_n(\diff s, 1)}{\hat{F}_n(s-, 0)}
      \right]
    \\
    & =
      \int_0^{\tau} w(s) 
      \Bigg\{
      \int_0^s 
      \left(
      \frac{1}{F(u-, 0)} -  \frac{1}{\hat{F}_n(u-, 0)}
      \right) F(\diff u, 2)
    \\
    & \qquad\qquad \qquad
      +
      \int_0^s \frac{1}{\hat{F}_n(u-, 0)} 
      \left[
      F(\diff u, 2) - \hat{F}_n(\diff u, 2)
      \right]
      \Bigg\}
    \\
    & \qquad\qquad \times
      \left[
      \left(
      \frac{1}{F(s-, 0)} -
      \frac{1}{\hat{F}_n(s-, 0)}
      \right)F(\diff s, 1)
       + \frac{1}{\hat{F}_n(s-, 0)}
      \left(
      F(\diff s, 1) -
      \hat{F}_n(\diff s, 1)
      \right)
      \right]
    \\
    &
      = \int_0^{\tau} 
      \int_0^s
      w(s) 
      \left(
      \frac{1}{F(u-, 0)} -  \frac{1}{\hat{F}_n(u-, 0)}
      \right) 
      \left(
      \frac{1}{F(s-, 0)} -
      \frac{1}{\hat{F}_n(s-, 0)}
      \right)F(\diff u, 2)F(\diff s, 1)
    \\
    & \quad +
      \int_0^{\tau}
      \int_0^s
      w(s) 
      \left(
      \frac{1}{F(u-, 0)} -  \frac{1}{\hat{F}_n(u-, 0)}
      \right) \frac{F(\diff u, 2) }{\hat{F}_n(u-,0)}
      \left(
      F(\diff s, 1) -
      \hat{F}_n(\diff s, 1)
      \right)
    \\
    & \quad +
      \int_0^{\tau} 
      \int_0^s      
      \frac{w(s) }{\hat{F}_n(u-, 0)} 
      \left[
      F(\diff u, 2) - \hat{F}_n(\diff u, 2)
      \right]
      \left(
      \frac{1}{F(s-, 0)} -
      \frac{1}{\hat{F}_n(s-, 0)}
      \right)F(\diff s, 1)
    \\
    & \quad +
      \int_0^{\tau} 
      \int_0^s      
      \frac{w(s) }{\hat{F}_n(u-, 0)} 
      \left[
      F(\diff u, 2) - \hat{F}_n(\diff u, 2)
      \right]
      \frac{1}{\hat{F}_n(s-, 0)}
      \left(
      F(\diff s, 1) -
      \hat{F}_n(\diff s, 1)
      \right).
  \end{align*}
  Consider the first term on the right hand side. Defining
  \begin{equation*}
    w_n^*(t)  = 
    \left(
      F(t-, 0)
      - \hat{F}_n(t-, 0)
    \right)
    \left(
      \frac{1}{F(t-, 0)}
      - \frac{1}{\hat{F}_n(t-, 0)}
    \right),
  \end{equation*}
  we can write
  \begin{align*}
    & \int_0^{\tau} 
      \int_0^s
      w(s) 
      \left(
      \frac{1}{F(u-, 0)} -  \frac{1}{\hat{F}_n(u-, 0)}
      \right)      
      \left(
      \frac{1}{F(s-, 0)} -
      \frac{1}{\hat{F}_n(s-, 0)}
      \right)F(\diff u, 2)F(\diff s, 1)
    \\
    & =
      \int_0^{\tau} 
      \int_0^s
      w(s)
      w_n^*(u) 
      \left(
      F(u-, 0) - \hat{F}_n(u-, 0)
      \right)
    \\
    & \qquad \qquad \quad
      \times
      w_n^*(s) 
      \left(
      F(s-, 0) - \hat{F}_n(s-, 0)
      \right)       
      F(\diff u, 2)F(\diff s, 1)
    \\
    & =
      \int_0^{\tau} 
      \int_0^s
      w_n^a(s,u)
      \left(
      F(u-, 0) - \hat{F}_n(u-, 0)
      \right)
      \left(
      F(s-, 0) - \hat{F}_n(s-, 0)
      \right)       
      F(\diff u, 2)F(\diff s, 1),
  \end{align*}
  where we have defined \( w_n^a(s,u) = w(s)w^*_n(s)w^*_n(u) \). By assumption,
  \( w_n^a(s,u) \) is uniformly bounded. The same approach can be applied to the
  three remaining terms which gives the result.
\end{proof}

\end{appendices}

\bibliographystyle{abbrvnat}
\bibliography{bib.bib}

\end{document}